{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:</h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Text Analysis</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)</b> (moodle example)<br/>\n",
    "&#x2714; <b>(brief review) All previous notebooks</b><br/>\n",
    "</div> \n",
    "<h5><u>Review the presentations regarding the following topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis</b> (lecture presentation)<br/>\n",
    "&#x2714; <b>(brief review) All other presentations</b><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2 ,mutual_info_classif\n",
    "from sklearn.model_selection import  cross_validate ,RepeatedKFold , RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import StackingClassifier , BaggingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis and String manipulation imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net installation:\n",
    "\n",
    "# unmark if you want to use and need to install\n",
    "#!pip install wn\n",
    "#!python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "#import wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer installation:\n",
    "\n",
    "# unmark if you want to use and need to install:\n",
    "#!pip install hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "#import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story gender\n",
       "0  כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...      m\n",
       "1  לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...      m\n",
       "2  מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...      f\n",
       "3  כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...      m\n",
       "4  ‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...      f\n",
       "5  לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...      f\n",
       "6  אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...      m\n",
       "7  השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...      f"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(753, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>שלום לכולם, בשנה הסוערת האחרונה בחרתי להציע לא...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>בסמסטר קודם אני וכמה חברים ללימודים קבענו להיפ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>אחרי 7 שנים החלטתי והרגשתי שהגיע הזמן למסד את ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>אני גולש קייט כבר 3 שנים, הספורט הזה תמיד עניי...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>ביום שבו נולדתי התברר לצוות הרפואי שערך בדיקות...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>אחרי הלימודים ביום שני נסעתי עם בת הזוג שלי בה...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>לפני שנתיים כשהיתתי בן 24 נסעתי עם האוטו שלי ל...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>בתחילת הקורנה באזור הסגר הראשון אני ובת הזוג ש...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>יום חמישי רגיל, תמיד מתחיל לעבור טיפה מאוחר יו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>בגלל כל המצב של הקורונה בארץ, הרבה זמן היינו ב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>במהלך הקורונה אני ומי שהיה בן זוגי רבנו הרבה, ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>הורי חוגגים יומולדת בהפרש של שבועיים לפני 6 שנ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>טסתי לספרד עם בת זוגתי לראות משחק כדורגל של הק...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>פורים מרץ 2020. עומלת חודש מראש על מנת למצוא ת...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>בחודשי הקיץ אני ואימי נסענו לספארי. הספארי ממו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>אני רוצה לספר לכם על חוויה שקרתה בחודשי הקיץ. ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>לאחר שחזרנו חזרה לשנת הלימודים במכללה הודיעו ל...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>בספטמבר 2020 בת זוג שלי לשעבר ואני נסענו לסופ\"...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>לפני כשנה כשהתחילה הקורונה החלטתי להעשיר את הי...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>בשירות הצבאי שלי עבדתי כמפתחת תוכנה. לקראת סוף...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>הסיפור הזה התרחקש כשאר הייתי בדרום אמריקה, זה ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>לאחר השחרור מהצבא החלטתי לצאת לטיול הגדול כמו ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>בשנה האחרונה חפשתי דירה להשקעה בראשון לציון, ע...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>יום אחד במהלך חופשת חנוכה הלכנו כמה חברים לשחק...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>הכל התחיל שקולגה לעבודה סיפר לי שהוא פיתח בוט ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>זה קרה לפני כמה חודשים, אני יושב בסלון ורואה ח...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>בסמסטר קיץ האחרון בגלל הקורונה נמנע ממני לעובד...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>לפני כחמש שנים במהלך טיול לאחר שירותי הצבאי, ט...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>גביע קמדן - הסיפור שלי מתחיל לפני כשמונה חודשי...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>מאז אמצע השנה הראשונה ללימודים אני והחברים יוצ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>לפני שנה וחצי טסטי לאוסטריה עם המשפחה שלי (אבא...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>בתחילת חודש ינואר עזבתי את עבודתי בנסיבות לא מ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>בחודש אוגוסט בשיאו של הגל הרביעי של מחלת הקורו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>באחד הסגרים שהיו , החלטתי שאני לא מסוגל יותר ל...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>נרשמתי השנה לתוכנית נינגה ישראל. אני מתאמן באו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>כשהנחת את ראשך בחיקי, גלגלתי ניחומים לעברך, וב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>אני הייתי בין הראשונים שהיו חולי קורונה בארץ ה...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>אני עובד בעבודה שמתעסקת בתיקון מחסנים חכמים..ע...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>כמעט נחטפתי בעזה. כשהתחיל עופתר יצוקה אנחנו הי...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>באחד מימי עבודתי לקראת יום הבחירות וחג הפסח שמ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>בחודש פברואר בשנת 2020 ממש לפני שהתחילה הקורונ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>מהקיץ בערך אנחנו מדברים החברים על טיסה לחופשת ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>בחודש האחרון נקראתי למילואים, דבר שלא קרה קודם...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>זה היה יום חורפי במרכז הארץ ראיתי את השלג יורד...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>במהלך השנה רכשתי דירה שזקוקה לשיפוץ מסיבי, השי...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>השנה ביקרתי באיטליה ברומא. נחתתי בלילה וחיכה ל...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>בשנה ב' ללימודי מדעי המחשב במכללת HIT, נרשמתי ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>בשנה האחרונה לקחתי על עצמי משימה, לנסות למצוא ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>השנה עברתי את החוויה הכי גדולה וטהורה שיכולתי ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>שנת 2020 הייתה מטלטלת למדי בשבילי, עברתי הרבה ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>גרתי במשך תקופה ארוכה עם 3 שותפים כאשר אני בקו...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>בשנה האחרונה , פרצה מחלת הקורונה דבר שאף אחד ל...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>אז רציתי לספר לכם חוויה שעברתי אני יודעת מראש ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>הכל התחיל אחרי הצבא, אני בן 21, סיימתי לא מזמן...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>בקיץ האחרון יצאתי לטיול עם חברים לטיול באיזור ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>אז לפני שנה בדיוק טסתי לאמסטרדם עם שני חברים ט...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>שבוע שעבר העליתי באופן ספונטני רעיון לנסוע עם ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>לפני חודש עברנו לדירה בבית שמש בעקבות משפחתי ה...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>החוויה אותה ארצה לשתף התרחשה לפני כמה חודשים, ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>פעם כשהייתי בחו\" \"ל ,בקבולומביה כחלק מהטיול של...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 story gender\n",
       "693  שלום לכולם, בשנה הסוערת האחרונה בחרתי להציע לא...      m\n",
       "694  בסמסטר קודם אני וכמה חברים ללימודים קבענו להיפ...      m\n",
       "695  אחרי 7 שנים החלטתי והרגשתי שהגיע הזמן למסד את ...      m\n",
       "696  אני גולש קייט כבר 3 שנים, הספורט הזה תמיד עניי...      m\n",
       "697  ביום שבו נולדתי התברר לצוות הרפואי שערך בדיקות...      m\n",
       "698  אחרי הלימודים ביום שני נסעתי עם בת הזוג שלי בה...      m\n",
       "699  לפני שנתיים כשהיתתי בן 24 נסעתי עם האוטו שלי ל...      m\n",
       "700  בתחילת הקורנה באזור הסגר הראשון אני ובת הזוג ש...      m\n",
       "701  יום חמישי רגיל, תמיד מתחיל לעבור טיפה מאוחר יו...      m\n",
       "702  בגלל כל המצב של הקורונה בארץ, הרבה זמן היינו ב...      m\n",
       "703  במהלך הקורונה אני ומי שהיה בן זוגי רבנו הרבה, ...      f\n",
       "704  הורי חוגגים יומולדת בהפרש של שבועיים לפני 6 שנ...      f\n",
       "705  טסתי לספרד עם בת זוגתי לראות משחק כדורגל של הק...      m\n",
       "706  פורים מרץ 2020. עומלת חודש מראש על מנת למצוא ת...      f\n",
       "707  בחודשי הקיץ אני ואימי נסענו לספארי. הספארי ממו...      m\n",
       "708  אני רוצה לספר לכם על חוויה שקרתה בחודשי הקיץ. ...      m\n",
       "709  לאחר שחזרנו חזרה לשנת הלימודים במכללה הודיעו ל...      m\n",
       "710  בספטמבר 2020 בת זוג שלי לשעבר ואני נסענו לסופ\"...      m\n",
       "711  לפני כשנה כשהתחילה הקורונה החלטתי להעשיר את הי...      f\n",
       "712  בשירות הצבאי שלי עבדתי כמפתחת תוכנה. לקראת סוף...      f\n",
       "713  הסיפור הזה התרחקש כשאר הייתי בדרום אמריקה, זה ...      m\n",
       "714  לאחר השחרור מהצבא החלטתי לצאת לטיול הגדול כמו ...      f\n",
       "715  בשנה האחרונה חפשתי דירה להשקעה בראשון לציון, ע...      m\n",
       "716  יום אחד במהלך חופשת חנוכה הלכנו כמה חברים לשחק...      m\n",
       "717  הכל התחיל שקולגה לעבודה סיפר לי שהוא פיתח בוט ...      m\n",
       "718  זה קרה לפני כמה חודשים, אני יושב בסלון ורואה ח...      m\n",
       "719  בסמסטר קיץ האחרון בגלל הקורונה נמנע ממני לעובד...      m\n",
       "720  לפני כחמש שנים במהלך טיול לאחר שירותי הצבאי, ט...      m\n",
       "721  גביע קמדן - הסיפור שלי מתחיל לפני כשמונה חודשי...      m\n",
       "722  מאז אמצע השנה הראשונה ללימודים אני והחברים יוצ...      m\n",
       "723  לפני שנה וחצי טסטי לאוסטריה עם המשפחה שלי (אבא...      f\n",
       "724  בתחילת חודש ינואר עזבתי את עבודתי בנסיבות לא מ...      m\n",
       "725  בחודש אוגוסט בשיאו של הגל הרביעי של מחלת הקורו...      m\n",
       "726  באחד הסגרים שהיו , החלטתי שאני לא מסוגל יותר ל...      m\n",
       "727  נרשמתי השנה לתוכנית נינגה ישראל. אני מתאמן באו...      m\n",
       "728  כשהנחת את ראשך בחיקי, גלגלתי ניחומים לעברך, וב...      m\n",
       "729  אני הייתי בין הראשונים שהיו חולי קורונה בארץ ה...      m\n",
       "730  אני עובד בעבודה שמתעסקת בתיקון מחסנים חכמים..ע...      m\n",
       "731  כמעט נחטפתי בעזה. כשהתחיל עופתר יצוקה אנחנו הי...      m\n",
       "732  באחד מימי עבודתי לקראת יום הבחירות וחג הפסח שמ...      m\n",
       "733  בחודש פברואר בשנת 2020 ממש לפני שהתחילה הקורונ...      f\n",
       "734  מהקיץ בערך אנחנו מדברים החברים על טיסה לחופשת ...      m\n",
       "735  בחודש האחרון נקראתי למילואים, דבר שלא קרה קודם...      m\n",
       "736  זה היה יום חורפי במרכז הארץ ראיתי את השלג יורד...      m\n",
       "737  במהלך השנה רכשתי דירה שזקוקה לשיפוץ מסיבי, השי...      f\n",
       "738  השנה ביקרתי באיטליה ברומא. נחתתי בלילה וחיכה ל...      m\n",
       "739  בשנה ב' ללימודי מדעי המחשב במכללת HIT, נרשמתי ...      m\n",
       "740  בשנה האחרונה לקחתי על עצמי משימה, לנסות למצוא ...      m\n",
       "741  השנה עברתי את החוויה הכי גדולה וטהורה שיכולתי ...      f\n",
       "742  שנת 2020 הייתה מטלטלת למדי בשבילי, עברתי הרבה ...      m\n",
       "743  גרתי במשך תקופה ארוכה עם 3 שותפים כאשר אני בקו...      f\n",
       "744  בשנה האחרונה , פרצה מחלת הקורונה דבר שאף אחד ל...      m\n",
       "745  אז רציתי לספר לכם חוויה שעברתי אני יודעת מראש ...      f\n",
       "746  הכל התחיל אחרי הצבא, אני בן 21, סיימתי לא מזמן...      m\n",
       "747  בקיץ האחרון יצאתי לטיול עם חברים לטיול באיזור ...      m\n",
       "748  אז לפני שנה בדיוק טסתי לאמסטרדם עם שני חברים ט...      m\n",
       "749  שבוע שעבר העליתי באופן ספונטני רעיון לנסוע עם ...      m\n",
       "750  לפני חודש עברנו לדירה בבית שמש בעקבות משפחתי ה...      m\n",
       "751  החוויה אותה ארצה לשתף התרחשה לפני כמה חודשים, ...      f\n",
       "752  פעם כשהייתי בחו\" \"ל ,בקבולומביה כחלק מהטיול של...      m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(8)\n",
    "df_train.shape\n",
    "df_train.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_example_id                                              story\n",
       "0                0  כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...\n",
       "1                1  הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...\n",
       "2                2  אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(323, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>רגע הגיוס לצבא היה הרגע הכי משמעותי עבורי, אני...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>אני הגעתי לברזיל ישר מקולומביה וגם אני עשיתי ע...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>בשנה האחרונה הרגשתי די תקוע בעבודה, השגרה הפכה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>אני ואילן חברים טובים מזה 20 שנה תמיד חלמנו לפ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>מידי יום שישי אני נוהג לנסוע בתחבורה ציבורית ס...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>לפני מספר חודשים, בשיא התחלואה של הגל השני, עמ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>היום בו דיווחתי על גניבה של האוטו שלי. בוקר אח...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_example_id                                              story\n",
       "0                  0  כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...\n",
       "1                  1  הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...\n",
       "2                  2  אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...\n",
       "3                  3  רגע הגיוס לצבא היה הרגע הכי משמעותי עבורי, אני...\n",
       "4                  4  אני הגעתי לברזיל ישר מקולומביה וגם אני עשיתי ע...\n",
       "..               ...                                                ...\n",
       "318              318  בשנה האחרונה הרגשתי די תקוע בעבודה, השגרה הפכה...\n",
       "319              319  אני ואילן חברים טובים מזה 20 שנה תמיד חלמנו לפ...\n",
       "320              320  מידי יום שישי אני נוהג לנסוע בתחבורה ציבורית ס...\n",
       "321              321  לפני מספר חודשים, בשיא התחלואה של הגל השני, עמ...\n",
       "322              322  היום בו דיווחתי על גניבה של האוטו שלי. בוקר אח...\n",
       "\n",
       "[323 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)\n",
    "df_test.shape\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students Names: Tal Damari and Adar Azulay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_clean_text function is cleaning our text from numeric numbers, dots etc.\n",
    "custom_preprocessor is removing non hebrew characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clean_text(df_series):\n",
    "    for indx in df_series.index:\n",
    "        df_series[\"story\"][indx] = re.sub(r'\\d+', '', df_series[\"story\"][indx])\n",
    "        df_series[\"story\"][indx] = re.sub(r'[^\\w\\s]', '', df_series[\"story\"][indx])\n",
    "        df_series[\"story\"][indx] = re.sub(r'\\s+', ' ', df_series[\"story\"][indx])\n",
    "        df_series[\"story\"][indx] = df_series[\"story\"][indx].strip()\n",
    "    return df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_clean_text(df_train)\n",
    "df_test = df_clean_text(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function is making train test split to our data set, after we \"cleaned\" it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_func(df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"story\"], df[\"gender\"], test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_func(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that makes a preprocessing to our dataset that makes it to be a TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfidfVectorizer_func(X_train, X_test, ngram_range = (1,1), min_df = 5):\n",
    "    #df_train_copy = df_train[\"story\"]\n",
    "    count_idf = TfidfVectorizer(min_df = min_df, ngram_range=ngram_range) #creating an object idfvectorizer\n",
    "    X_train_idf = count_idf.fit_transform(X_train)\n",
    "    X_test_idf = count_idf.transform(X_test)\n",
    "    return X_train_idf, X_test_idf # return the new dataset with the idf values for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preform a selector for our dataset that will make feature selection in our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features(X_train, X_test, y_train, k=1000):\n",
    "    select_best = SelectKBest(mutual_info_classif, k=k)\n",
    "    select_best.fit(X_train, y_train)\n",
    "    \n",
    "    X_train_select = select_best.transform(X_train)\n",
    "    X_test_select = select_best.transform(X_test)\n",
    "    return X_train_select, X_test_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function is using MinMaxScaler, to scale our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preform_MinMaxScale(X_train_select, X_test_select):\n",
    "    scale = MinMaxScaler()\n",
    "    X_train_scale = scale.fit_transform(X_train_select.toarray())\n",
    "    X_test_scale = scale.fit_transform(X_test_select.toarray())\n",
    "    return X_train_scale, X_test_scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idf, X_test_idf = TfidfVectorizer_func(X_train, X_test)\n",
    "X_train_select, X_test_select = select_best_features(X_train_idf, X_test_idf, y_train)\n",
    "X_train_scale, X_test_scale = preform_MinMaxScale(X_train_select, X_test_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best parameters for our model using GridSearchCV function, they will be implemented in different functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params_grid_search(model_clf, model_parameters, X_train, y_train):\n",
    "    grid_search = GridSearchCV(model_clf, model_parameters, cv = 5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation to get the best parameters for each model we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'dual': False, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001, 'penalty': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'alpha': 0.05,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001, 'loss': 'squared_hinge', 'penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Linear_svc_parmas = [{'C': [0.01, 0.1, 1, 10, 100], 'penalty': [None, 'l1', 'l2'], 'dual': [False]}]\n",
    "best_params_linear_svc = find_best_params_grid_search(LinearSVC(), Linear_svc_parmas, X_train_scale, y_train)\n",
    "best_params_linear_svc\n",
    "\n",
    "Perceptron_params = [{'alpha': [0.0001, 0.05], 'penalty': [None, 'l2', 'l1', 'elasticnet']}]\n",
    "best_params_perceptron = find_best_params_grid_search(Perceptron(), Perceptron_params, X_train_scale, y_train)\n",
    "best_params_perceptron\n",
    "\n",
    "MultinomailNB_parmas = [{'alpha': [0.01, 0.1, 0.5, 1], 'fit_prior': [True, False], 'class_prior': [None, [0.5, 0.5], [0.3, 0.7]]}]\n",
    "best_params_MultinomialNB = find_best_params_grid_search(MultinomialNB(), MultinomailNB_parmas, X_train_scale, y_train)\n",
    "best_params_MultinomialNB\n",
    "\n",
    "MLP_params = [{'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)], 'activation': ['tanh', 'relu'],\n",
    "               'solver': ['sgd', 'adam'], 'alpha': [0.0001, 0.05], 'learning_rate': ['constant','adaptive']}]\n",
    "best_params_MLP = find_best_params_grid_search(MLPClassifier(),MLP_params, X_train_scale, y_train)\n",
    "best_params_MLP\n",
    "\n",
    "SGD_parmas = [{'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "               'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "               'alpha': [0.0001, 0.05]}]\n",
    "best_params_SGD = find_best_params_grid_search(SGDClassifier(), SGD_parmas, X_train_scale, y_train)\n",
    "best_params_SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the models were going to use with the best parameters the grid search has given us**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_model = LinearSVC(**best_params_linear_svc)  #linear model\n",
    "Perceptron_model = Perceptron(**best_params_perceptron) ##perceptron model\n",
    "MultinomialNB_model = MultinomialNB(**best_params_MultinomialNB) #Multinomial naive bayse model\n",
    "MLP_model = MLPClassifier(**best_params_MLP) #MLP model \n",
    "SGD_model = SGDClassifier(**best_params_SGD) #SGD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function is fitting and predicting the values that the model is giving us, and returning us the model with the f1_score as being asked f1_average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_evaluate(model_name, X_train, X_test, y_train, y_test):\n",
    "    model_trained = model_name.fit(X_train, y_train) #fitting our model with the train values\n",
    "    \n",
    "    cv = RepeatedKFold(n_splits= 5, n_repeats=3, random_state=42) #using different amount of folds for cross_vald_score function\n",
    "    f1_scorer = make_scorer(f1_score, average='micro')\n",
    "    scores = cross_val_score(model_trained, X_test, y_test, scoring = f1_scorer, cv = cv, n_jobs=-1)\n",
    "    \n",
    "    scores \n",
    "    \n",
    "    y_pred = model_trained.predict(X_test)\n",
    "    print(y_pred)\n",
    "    \n",
    "    f1_male = f1_score(y_test, y_pred, pos_label=\"m\")\n",
    "    f1_female = f1_score(y_test, y_pred, pos_label=\"f\")\n",
    "    f1_average = (f1_male+f1_female)/2\n",
    "    \n",
    "    return model_trained, f1_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next cell is using the above cell, and showing our model predictions correctioness using f1_score_average as being asked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, dual=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'f' 'f' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm'\n",
      " 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm'\n",
      " 'f' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'f' 'f' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'f'\n",
      " 'm' 'm' 'm' 'm' 'm' 'f' 'f' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm'\n",
      " 'f' 'f' 'f' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f'\n",
      " 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'm' 'm' 'f']\n",
      "f1_score Linear_svc:\n",
      "0.7082125603864735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'f' 'm' 'f' 'f' 'm' 'm' 'm' 'f' 'm' 'm'\n",
      " 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'f' 'f' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'f'\n",
      " 'm' 'm' 'm' 'm' 'f' 'f' 'f' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'f' 'm' 'f' 'm' 'm' 'm' 'f' 'f' 'm'\n",
      " 'f' 'm' 'f' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f'\n",
      " 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'f' 'm' 'f']\n",
      "f1_score perceptron:\n",
      "0.7010945505356312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'f' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'f' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm'\n",
      " 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'm' 'm' 'm']\n",
      "f1_score MultinomialNB:\n",
      "0.694566506242589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.05, learning_rate='adaptive')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'f' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm'\n",
      " 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm'\n",
      " 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f'\n",
      " 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'm' 'm' 'f']\n",
      "f1_score MLP:\n",
      "0.6955645161290323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='squared_hinge', penalty='elasticnet')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m' 'm' 'm' 'f' 'f' 'm' 'm' 'f' 'f' 'f' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm'\n",
      " 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'f' 'f' 'm' 'm' 'm' 'm' 'm'\n",
      " 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'f' 'f' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'f' 'f' 'm' 'm' 'f' 'm' 'f' 'f'\n",
      " 'f' 'm' 'm' 'm' 'f' 'm' 'f' 'f' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'm' 'm' 'm'\n",
      " 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'f' 'f' 'f' 'm' 'm' 'm' 'm' 'm' 'f' 'f' 'm'\n",
      " 'f' 'f' 'f' 'm' 'f' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'f' 'f' 'm' 'm' 'f'\n",
      " 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'f' 'm' 'm' 'm' 'm' 'm' 'f' 'f' 'f' 'm' 'm'\n",
      " 'm' 'm' 'm' 'm' 'f' 'm' 'm']\n",
      "f1_score SGD:\n",
      "0.7073643410852712\n"
     ]
    }
   ],
   "source": [
    "Linear_model\n",
    "linear_trained, f1_average_linear = fit_predict_evaluate(Linear_model, X_train_scale, X_test_scale, y_train, y_test)\n",
    "print(\"f1_score Linear_svc:\")\n",
    "print(f1_average_linear)\n",
    "\n",
    "Perceptron_model\n",
    "perceptorn_trained, f1_average_perceptron = fit_predict_evaluate(Perceptron_model, X_train_scale, X_test_scale, y_train, y_test)\n",
    "print(\"f1_score perceptron:\")\n",
    "print(f1_average_perceptron)\n",
    "\n",
    "MultinomialNB_model\n",
    "MultinomialNB_trained, f1_average_MultinomialNB = fit_predict_evaluate(MultinomialNB_model, X_train_scale, X_test_scale, y_train, y_test)\n",
    "print(\"f1_score MultinomialNB:\")\n",
    "print(f1_average_MultinomialNB)\n",
    "\n",
    "MLP_model\n",
    "MLP_trained, f1_average_MLP = fit_predict_evaluate(MLP_model, X_train_scale, X_test_scale, y_train, y_test)\n",
    "print(\"f1_score MLP:\")\n",
    "print(f1_average_MLP)\n",
    "\n",
    "SGD_model\n",
    "SGD_trained, f1_average_SGD = fit_predict_evaluate(SGD_model, X_train_scale, X_test_scale, y_train, y_test)\n",
    "print(\"f1_score SGD:\")\n",
    "print(f1_average_SGD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cells are for the df_test to predict and to finish the Assignment :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfidfVectorizer_func_test(X, ngram_range = (1,1), min_df = 5):\n",
    "    count_idf = TfidfVectorizer(min_df = min_df, ngram_range=ngram_range) #creating an object idfvectorizer\n",
    "    X = count_idf.fit_transform(X)\n",
    "    return X # return the new dataset with the idf values for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features_test(X, k=1000):\n",
    "    select_best = SelectKBest(mutual_info_classif, k=k)\n",
    "    X_test_selected = select_best.fit_transform(X, np.zeros(X.shape[0]))\n",
    "    return X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preform_MinMaxScale_test(X_train_select):\n",
    "    scale = MinMaxScaler()\n",
    "    X_train_scale = scale.fit_transform(X_train_select.toarray())\n",
    "    return X_train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m', 'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'f', 'f', 'm',\n",
       "       'f', 'm', 'm', 'f', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'f', 'm', 'm', 'f', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'f',\n",
       "       'm', 'm', 'f', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'f', 'f', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'f', 'm', 'f', 'm', 'f', 'm', 'f', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'f', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'f',\n",
       "       'm', 'f', 'm', 'm', 'm', 'f', 'f', 'f', 'm', 'm', 'm', 'm', 'f',\n",
       "       'm', 'm', 'm', 'f', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'f', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'f',\n",
       "       'm', 'm', 'f', 'f', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'f', 'f',\n",
       "       'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'f', 'm', 'f', 'm', 'm', 'm', 'f', 'f', 'm', 'm', 'm', 'm',\n",
       "       'm', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'f', 'm', 'm', 'f', 'm',\n",
       "       'f', 'm', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'f', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'f',\n",
       "       'f', 'm', 'm', 'f', 'm', 'm', 'f', 'm', 'm', 'm', 'm', 'm', 'm',\n",
       "       'm', 'f', 'm', 'f', 'm', 'm', 'm', 'f', 'f', 'm', 'm'], dtype='<U1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test only:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_example_id predicted_category\n",
       "0                  0                  m\n",
       "1                  1                  m\n",
       "2                  2                  m\n",
       "3                  3                  m\n",
       "4                  4                  m\n",
       "..               ...                ...\n",
       "318              318                  m\n",
       "319              319                  f\n",
       "320              320                  f\n",
       "321              321                  m\n",
       "322              322                  m\n",
       "\n",
       "[323 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_test = df_test[\"story\"]  #X_df_test has only the stories \n",
    "X_df_test = TfidfVectorizer_func_test(X_df_test) #using TF - IDF vectorizer\n",
    "X_df_test = select_best_features_test(X_df_test) #feature selector for the k best features of the dataset\n",
    "X_df_test = preform_MinMaxScale_test(X_df_test) #minmax scaling \n",
    "\n",
    "y_prediction_test = SGD_trained.predict(X_df_test)  #predicting on the df_test\n",
    "y_prediction_test #printing the predictions \n",
    "\n",
    "df_text_exmp = df_test.test_example_id #creating an array with the text example id column in df test\n",
    "\n",
    "df_predicted = pd.DataFrame({\"test_example_id\":df_text_exmp.tolist(),\n",
    "                     \"predicted_category\": y_prediction_test.tolist()}) #creating a dataframe as wanted \n",
    "\n",
    "print(\"Test only:\")\n",
    "df_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv (optional)\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
